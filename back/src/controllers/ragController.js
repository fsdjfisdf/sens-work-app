// back/src/controllers/ragController.js
const { openai, MODELS } = require('../../config/openai');
const {
  ensureTables,
  fetchAllEmbeddings,
  cosineSimilarity,
} = require('../dao/ragDao');

/** ì§ˆë¬¸ì—ì„œ SITE í‚¤ì›Œë“œ ìë™ ì¶”ë¡  (PT/HS/IC/CJ/PSKH) */
function inferSiteFromQuestion(q = '') {
  const U = String(q).toUpperCase();
  const tests = [
    { key: 'PT',   pats: [/\bPT\b/, ' PT ', 'PT ', ' PT', 'PTì‚¬ì´íŠ¸'] },
    { key: 'HS',   pats: [/\bHS\b/, ' HS ', 'HS ', ' HS', 'HSì‚¬ì´íŠ¸'] },
    { key: 'IC',   pats: [/\bIC\b/, ' IC ', 'IC ', ' IC', 'ICì‚¬ì´íŠ¸'] },
    { key: 'CJ',   pats: [/\bCJ\b/, ' CJ ', 'CJ ', ' CJ', 'CJì‚¬ì´íŠ¸'] },
    { key: 'PSKH', pats: [/\bPSKH\b/, ' PSKH ', 'PSKH ', ' PSKH', 'PSKHì‚¬ì´íŠ¸'] },
  ];
  for (const t of tests) {
    for (const p of t.pats) {
      if (p instanceof RegExp ? p.test(U) : U.includes(p)) return t.key;
    }
  }
  return null;
}

/** ì»¨í…ìŠ¤íŠ¸ ë¬¶ì–´ì„œ ë©”ì‹œì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± (contextsëŠ” string[] ê°€ì •) */
function buildPrompt(question, contexts) {
  const ctx = (contexts || [])
    .map((text, i) => `ã€ê·¼ê±° ${i + 1}ã€‘\n${text}`)
    .join('\n\n');

  return [
    {
      role: 'system',
      content:
        'ë„ˆëŠ” í˜„ì¥ ì‘ì—… ë¡œê·¸ ìš”ì•½/ê²€ìƒ‰ ë³´ì¡°ìì•¼. ì£¼ì–´ì§„ ê·¼ê±° ì•ˆì—ì„œë§Œ ë‹µí•˜ê³ , ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´. í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ. í•­ëª©ì€ ë¶ˆë¦¿ìœ¼ë¡œ ì •ë¦¬í•´.',
    },
    {
      role: 'user',
      content: [
        `ì§ˆë¬¸:\n${question}`,
        '------',
        'ê·¼ê±° ëª¨ìŒ:',
        ctx || '(ê·¼ê±° ì—†ìŒ)',
        '------',
        'ì§€ì¹¨:',
        '- ê·¼ê±°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ ê²ƒ',
        '- ìˆ˜ì¹˜/ì¡°ê±´ì€ ê·¼ê±°ì—ì„œ í™•ì¸ëœ ê²ƒë§Œ ì–¸ê¸‰',
        '- ë§ˆì§€ë§‰ ì¤„ì— "â€» ê·¼ê±°: nê±´" í‘œê¸°',
      ].join('\n'),
    },
  ];
}

/** í…ìŠ¤íŠ¸ ì •ë¦¬ (ë„ˆë¬´ ê¸´ ê³µë°±/HTML br ì •ë¦¬) */
function normalizeContent(s = '') {
  return String(s)
    .replace(/<br\s*\/?>/gi, '\n')
    .replace(/\r/g, '')
    .replace(/\n{3,}/g, '\n\n')
    .trim();
}

async function ask(req, res) {
  try {
    const {
      question,
      topK: _topK = 20,
      prefilterLimit: _prefilter = 300,
      days: _days = 365,
      filters = {},
    } = req.body || {};

    if (!question || !String(question).trim()) {
      return res.status(400).json({ ok: false, error: 'question is required' });
    }

    // ìˆ«ì íŒŒë¼ë¯¸í„° ì •ê·œí™”
    const topK = Math.max(1, Math.min(50, Number(_topK) || 20));
    const prefilterLimit = Math.max(10, Math.min(5000, Number(_prefilter) || 300));
    const days = Math.max(1, Math.min(3650, Number(_days) || 365)); // ìµœëŒ€ 10ë…„

    await ensureTables();

    // ğŸ” ì§ˆë¬¸ì—ì„œ SITE ìë™ ì¶”ë¡  (í”„ë¡ íŠ¸ê°€ filters.site ì•ˆ ë³´ë‚¼ ë•Œ ë³´ì •)
    const inferredSite = (!filters.site) ? inferSiteFromQuestion(question) : null;
    const effectiveFilters = {
      ...filters,
      ...(inferredSite ? { site: inferredSite } : {}),
      days, // ë‚ ì§œ í•„í„° ì „ë‹¬ (DAOì—ì„œ NULL í—ˆìš© ì²˜ë¦¬í•¨)
    };

    // 1) í›„ë³´ ë¡œë”©
    let candidates = await fetchAllEmbeddings({
      filters: effectiveFilters,
      limit: prefilterLimit,
    });

    // âš–ï¸ í›„ë³´ 0ì´ë©´ ë‚ ì§œ í•„í„° ì œê±°í•´ ì¬ì‹œë„ (ì´ˆê¸° NULL task_date ë°ì´í„° êµ¬ì œ)
    if (!candidates.length) {
      const { days: _ignored, ...noDaysFilters } = effectiveFilters;
      candidates = await fetchAllEmbeddings({
        filters: noDaysFilters,
        limit: Math.max(prefilterLimit, 1000), // í•œë²ˆ ë” ë„‰ë„‰íˆ
      });
      if (!candidates.length) {
        console.warn('[RAG] no candidates after fetchAllEmbeddings. filters=%j, prefilter=%d', effectiveFilters, prefilterLimit);
        return res.json({
          ok: true,
          used: { model: { chat: MODELS.chat, embedding: MODELS.embedding } },
          answer: 'ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.',
          evidence_preview: [],
        });
      }
    }

    // 2) ì¿¼ë¦¬ ì„ë² ë”©
    const emb = await openai.embeddings.create({
      model: MODELS.embedding,
      input: [String(question)],
    });
    const qVec = emb.data?.[0]?.embedding || [];

    // 3) ìœ ì‚¬ë„ ê³„ì‚° ë° ì •ë ¬
    const ranked = candidates
      .map(c => ({
        ...c,
        score: cosineSimilarity(qVec, c.embedding),
      }))
      .sort((a, b) => b.score - a.score)
      .slice(0, topK);

    // 4) ë¹ˆ ì»¨í…ì¸  ì œì™¸(LLM ì»¨í…ìŠ¤íŠ¸/ìš”ì•½ ëª¨ë‘)
    const rankedNonEmpty = ranked.filter(r => (r.content && String(r.content).trim().length > 0));

    // ëª¨ë¸ì— ë“¤ì–´ê°ˆ ì»¨í…ìŠ¤íŠ¸ëŠ” ìµœëŒ€ 8ê°œ (í† í° ì•ˆì „ì¥ì¹˜)
    const contextsForLLM = rankedNonEmpty.slice(0, 8).map(r => normalizeContent(r.content));
    const ctxUsedCount = contextsForLLM.length;

    // 5) í”„ë¦¬ë·°(í”„ë¡ íŠ¸ í…Œì´ë¸”ìš©) êµ¬ì„±
    const evidence_preview = ranked.map(r => ({
      id: r.chunk_id,
      date: r.task_date ? String(r.task_date).slice(0, 10) : '',
      site: r.site || '',
      line: r.line || '',
      eq: [r.equipment_type, r.equipment_name].filter(Boolean).join(' / '),
      sim: r.score || 0,
      name: r.work_type
        ? `${r.work_type}${r.work_type2 ? ' / ' + r.work_type2 : ''}`
        : '',
      desc: normalizeContent(r.content || '').slice(0, 180),
    }));

    // 6) ì»¨í…ìŠ¤íŠ¸ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ëª¨ë¸ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì•ˆë‚´
    if (ctxUsedCount === 0) {
      return res.json({
        ok: true,
        used: { model: { chat: MODELS.chat, embedding: MODELS.embedding } },
        answer: 'ì£„ì†¡í•˜ì§€ë§Œ, ì œê³µëœ ê·¼ê±° í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nâ€» ê·¼ê±°: 0ê±´',
        evidence_preview,
      });
    }

    // 7) ëª¨ë¸ í˜¸ì¶œ
    const messages = buildPrompt(question, contextsForLLM);
    const chatRes = await openai.chat.completions.create({
      model: MODELS.chat,
      messages,
      temperature: 0.2,
    });

    const rawAnswer = chatRes.choices?.[0]?.message?.content?.trim();
    const answer = rawAnswer
      ? `${rawAnswer}\n\nâ€» ê·¼ê±°: ${ctxUsedCount}ê±´`
      : `ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\nâ€» ê·¼ê±°: ${ctxUsedCount}ê±´`;

    // 8) ì‘ë‹µ
    return res.json({
      ok: true,
      used: { model: { chat: MODELS.chat, embedding: MODELS.embedding } },
      answer,
      evidence_preview,
    });

  } catch (err) {
    console.error('[RAG] ask error:', err);
    return res.status(500).json({ ok: false, error: String(err?.message || err) });
  }
}

module.exports = { ask };
